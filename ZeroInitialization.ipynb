{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Zero Initialization - Bias Initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from torch.optim import Adam, RMSprop, SGD\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from config import ExperimentConfig\n",
    "from data import get_mnist_loader, get_cifar10_loader\n",
    "from models import FNN, CNN, CIFARCNN\n",
    "from train import run_experiments, Trainer\n",
    "from utils import plot_comparison\n",
    "\n",
    "ELU_SCALE = math.sqrt(1.55)\n",
    "RELU_SCALE = math.sqrt(2)\n",
    "R_SEED = 1777"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 MNIST - FNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Normal Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\")\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_NORMAL\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", softmax_init=True)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_NORMAL_LAST_LAYER\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", scale_factor=ELU_SCALE)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_NORMAL_ELU_SCALE\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", scale_factor=0.1)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_NORMAL_0.1\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", scale_factor=0.5)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_NORMAL_0.5\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", scale_factor=2)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_NORMAL_2.0\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal_in_features\")\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_NORMAL_IN_FEATURES\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal_in_features\", softmax_init=True)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_NORMAL_IN_FEATURES_LAST_LAYER\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    summary_paths=[\n",
    "        os.path.join(\"results\", \"MNIST_FNN\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_NORMAL\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_NORMAL_LAST_LAYER\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_NORMAL_ELU_SCALE\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_NORMAL_0.1\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_NORMAL_0.5\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_NORMAL_2.0\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_NORMAL_IN_FEATURES\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_NORMAL_IN_FEATURES_LAST_LAYER\"),\n",
    "    ],\n",
    "    n_runs=1,\n",
    "    n_epochs=15\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.1 Finding The Point Of Break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_1_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_1_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 400},\n",
    "            {\"in_features\": 400, \"out_features\": 300},\n",
    "            {\"in_features\": 300, \"out_features\": 150},\n",
    "            {\"in_features\": 150, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_2_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 400},\n",
    "            {\"in_features\": 400, \"out_features\": 300},\n",
    "            {\"in_features\": 300, \"out_features\": 150},\n",
    "            {\"in_features\": 150, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_2_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=8)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_3_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(120, 221, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 400},\n",
    "            {\"in_features\": 400, \"out_features\": 300},\n",
    "            {\"in_features\": 300, \"out_features\": 150},\n",
    "            {\"in_features\": 150, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_4_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Uniform Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.1 Zero To One Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=0, b=1)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_UNIFORM_0-1\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.2 Unit Variance And Zero Mean Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-1.73, b=1.73)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_UNIFORM_PRE_ACT\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.3 Unit Variance Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-1.29, b=2.5)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_UNIFORM_UNIT_VAR\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.4 Zero Mean Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-2.52, b=1.79)\n",
    "writer = SummaryWriter(\"./results/MNIST_FNN_UNIFORM_ZERO_MEAN\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.5 Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    summary_paths=[\n",
    "        os.path.join(\"results\", \"MNIST_FNN\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_UNIFORM_0-1\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_UNIFORM_PRE_ACT\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_UNIFORM_UNIT_VAR\"),\n",
    "        os.path.join(\"results\", \"MNIST_FNN_UNIFORM_ZERO_MEAN\"),\n",
    "    ],\n",
    "    n_runs=1,\n",
    "    n_epochs=15\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Compare Our Approach To Others"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_FNN_TRIAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_fnn.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_fnn.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"normal\")\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_FNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_fnn_normal.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_fnn_normal.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"uniform\", a=0, b=1)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_FNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_fnn_uniform.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_fnn_uniform.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 MNIST - CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Normal Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32, flatten=False)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32, flatten=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\")\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN_NORMAL\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal_in_features\")\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN_NORMAL_IN_FEATURES\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", scale_factor=ELU_SCALE)\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN_NORMAL_ELU_SCALE\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", softmax_init=True)\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN_NORMAL_LAST_LAYER\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal_in_features\", softmax_init=True)\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN_NORMAL_IN_FEATURES_LAST_LAYER\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    summary_paths=[\n",
    "        os.path.join(\"results\", \"MNIST_CNN\"),\n",
    "        os.path.join(\"results\", \"MNIST_CNN_NORMAL\"),\n",
    "        os.path.join(\"results\", \"MNIST_CNN_NORMAL_IN_FEATURES\"),\n",
    "        os.path.join(\"results\", \"MNIST_CNN_NORMAL_ELU_SCALE\"),\n",
    "        os.path.join(\"results\", \"MNIST_CNN_NORMAL_LAST_LAYER\"),\n",
    "        os.path.join(\"results\", \"MNIST_CNN_NORMAL_IN_FEATURES_LAST_LAYER\"),\n",
    "    ],\n",
    "    n_runs=1,\n",
    "    n_epochs=15\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.1 Finding The Point Of Break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(10, 31, 2)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_1_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(10, 31, 2)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 8, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 8, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 16 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_2_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(10, 31, 2)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_3_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(10, 31, 2)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 100},\n",
    "            {\"in_features\": 100, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_4_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Uniform Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32, flatten=False)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32, flatten=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.1 Zero To One Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"uniform\", a=0, b=1)\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN_UNIFORM_0-1\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.2 Unit Variance And Zero Mean Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(mode=\"uniform\", a=-1.73, b=1.73)\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN_UNIFORM_PRE_ACT\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.3 Unit Variance Activation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(mode=\"uniform\", a=-1.29, b=2.5)\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN_UNIFORM_UNIT_VAR\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.4 Zero Mean Activation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"uniform\", a=-2.52, b=1.79)\n",
    "\n",
    "writer = SummaryWriter(\"./results/MNIST_CNN_UNIFORM_ZERO_MEAN\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.5 Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    summary_paths=[\n",
    "        os.path.join(\"results\", \"MNIST_CNN\"),\n",
    "        os.path.join(\"results\", \"MNIST_CNN_UNIFORM_0-1\"),\n",
    "        os.path.join(\"results\", \"MNIST_CNN_UNIFORM_PRE_ACT\"),\n",
    "        os.path.join(\"results\", \"MNIST_CNN_UNIFORM_UNIT_VAR\"),\n",
    "        os.path.join(\"results\", \"MNIST_CNN_UNIFORM_ZERO_MEAN\"),\n",
    "    ],\n",
    "    n_runs=1,\n",
    "    n_epochs=15\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO do several runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Compare Our Approach To Others"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_CNN_TRIAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_cnn.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_cnn.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"normal\")\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_CNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_cnn_normal.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_cnn_normal.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"uniform\", a=0, b=1)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_CNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_cnn_uniform.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_cnn_uniform.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 CIFAR-10 - FNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Normal Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_cifar10_loader(train=True, batch_size=32)\n",
    "test_loader = get_cifar10_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=15\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=15\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=15\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", ELU_SCALE)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_ELU_SCALE\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=15\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal_in_features\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_IN_FEATURES\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=15\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal_in_features\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_IN_FEATURES_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=15\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    summary_paths=[\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN_NORMAL\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN_NORMAL_LAST_LAYER\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN_NORMAL_ELU_SCALE\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN_NORMAL_IN_FEATURES\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN_NORMAL_IN_FEATURES_LAST_LAYER\"),\n",
    "    ],\n",
    "    n_runs=5,\n",
    "    n_epochs=15\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.1 Finding The Point Of Break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_FNN_NORMAL_1_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_FNN_NORMAL_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Uniform Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_cifar10_loader(train=True, batch_size=32)\n",
    "test_loader = get_cifar10_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.1 Zero To One Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=0, b=1)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_FNN_UNIFORM_0-1\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.2 Unit Variance And Zero Mean Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-1.73, b=1.73)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_FNN_UNIFORM_PRE_ACT\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.3 Unit Variance Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-1.29, b=2.5)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_FNN_UNIFORM_UNIT_VAR\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.4 Zer Mean Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-2.52, b=1.79)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_FNN_UNIFORM_ZERO_MEAN\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.5 Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    summary_paths=[\n",
    "        # os.path.join(\"results\", \"CIFAR-10_FNN\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN_UNIFORM_0-1\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN_UNIFORM_PRE_ACT\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN_UNIFORM_UNIT_VAR\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_FNN_UNIFORM_ZERO_MEAN\"),\n",
    "    ],\n",
    "    n_runs=1,\n",
    "    n_epochs=30\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Compare Our Approach to Others"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_FNN_TRIAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_fnn.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_fnn.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"normal\", softmax_init=True)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_FNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_fnn_normal.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_fnn_normal.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"uniform\", a=0, b=1)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_FNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_fnn_uniform.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_fnn_uniform.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4 CIFAR-10 CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_cifar10_loader(train=True, batch_size=32, flatten=False)\n",
    "test_loader = get_cifar10_loader(train=False, batch_size=32, flatten=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Normal Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\")\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN_NORMAL\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", softmax_init=True)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN_NORMAL_LAST_LAYER\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", 1.55)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN_NORMAL_ELU_SCALE\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "model.initialize(\"normal_in_features\")\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN_NORMAL_IN_FEATURES\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "model.initialize(\"normal_in_features\", softmax_init=True)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN_NORMAL_IN_FEATURES_LAST_LAYER\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    summary_paths=[\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN_NORMAL\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN_NORMAL_LAST_LAYER\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN_NORMAL_ELU_SCALE\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN_NORMAL_IN_FEATURES\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN_NORMAL_IN_FEATURES_LAST_LAYER\"),\n",
    "    ],\n",
    "    n_runs=1,\n",
    "    n_epochs=30\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.1.1 Finding The Point of Break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CIFARCNN()\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_CNN_NORMAL_1_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = CIFARCNN()\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_CNN_NORMAL_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Uniform Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_cifar10_loader(train=True, batch_size=32, flatten=False)\n",
    "test_loader = get_cifar10_loader(train=False, batch_size=32, flatten=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.1 Zero To One Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "model.initialize(mode=\"uniform\", a=0, b=1)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN_UNIFORM_0-1\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.2 Unit Variance And Zero Mean Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "model.initialize(mode=\"uniform\", a=-1.73, b=1.73)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN_UNIFORM_PRE_ACT\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.3 Unit Variance Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "model.initialize(mode=\"uniform\", a=-1.29, b=2.5)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN_UNIFORM_UNIT_VAR\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.4 Zero Mean Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = CIFARCNN()\n",
    "model.initialize(mode=\"uniform\", a=-2.52, b=1.79)\n",
    "writer = SummaryWriter(f\"./results/CIFAR-10_CNN_UNIFORM_ZERO_MEAN\")\n",
    "trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.5 Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    summary_paths=[\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN_UNIFORM_0-1\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN_UNIFORM_PRE_ACT\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN_UNIFORM_UNIT_VAR\"),\n",
    "        os.path.join(\"results\", \"CIFAR-10_CNN_UNIFORM_ZERO_MEAN\"),\n",
    "    ],\n",
    "    n_runs=1,\n",
    "    n_epochs=30\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Compare Our Approach To Others"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CIFARCNN()\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_CNN_TRIAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_cnn.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_cnn.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CIFARCNN()\n",
    "    model.initialize(\"normal_in_features\")\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_CNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_cnn_normal.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_cnn_normal.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CIFARCNN()\n",
    "    model.initialize('uniform', a=0, b=1)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_CNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_cnn_uniform.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_cnn_uniform.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO REMOVE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import ELU\n",
    "\n",
    "b = torch.tensor(np.linspace(-2.52242, 1.79035, 1_000))\n",
    "b = torch.tensor(np.linspace(-1.29, 2.5, 1_000))\n",
    "# b = torch.tensor(np.linspace(-2.9, 2, 1_000))\n",
    "# b = torch.tensor(np.linspace(-1.73, 1.73, 1_000))\n",
    "\n",
    "x = ELU()(b)\n",
    "# x = b\n",
    "print(f\"E[x] = {torch.mean(x)}\")\n",
    "print(f\"VAR[x] {torch.var(x)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
