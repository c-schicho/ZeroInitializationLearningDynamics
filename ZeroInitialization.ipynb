{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Zero Initialization - Bias Initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from torch.optim import Adam, RMSprop, SGD\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from config import ExperimentConfig\n",
    "from data import get_mnist_loader, get_cifar10_loader\n",
    "from models import FNN, CNN, CIFARCNN, ResNet50\n",
    "from train import run_experiments, Trainer\n",
    "\n",
    "ELU_SCALE_NORMAL = math.sqrt(1.615)\n",
    "ELU_SCALE_UNIFORM = math.sqrt(1.574)\n",
    "RELU_SCALE = math.sqrt(2)\n",
    "R_SEED = 1777"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 MNIST - FNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Normal Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.1 Pytorch Default Initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.2 Standard Normal Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.3 Negative Mean Shift"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", mean=-1.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_MEAN_NEG\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.4 Positive Mean Shift"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", mean=1.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_MEAN_POS\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.5 Negative Mean Shift High"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)\n",
    "\n",
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", mean=-5.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_NEG_HIGH\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.6 Positive Mean Shift High"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", mean=5.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_MEAN_POS_HIGH\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.7 Negative Mean Shift very High"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", mean=-50.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_MEAN_NEG_OVER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.8 Positive Mean Shift very High"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", mean=50.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_MEAN_POS_OVER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", scale_factor=ELU_SCALE_NORMAL)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_ELU_SCALE\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", scale_factor=0.1)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_0.1_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", scale_factor=0.5)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_0.5_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal\", scale_factor=2)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_2.0_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal_in_features\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_IN_FEATURES\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"normal_in_features\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_NORMAL_IN_FEATURES_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.1 Finding The Point Of Break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_1_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_1_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 400},\n",
    "            {\"in_features\": 400, \"out_features\": 300},\n",
    "            {\"in_features\": 300, \"out_features\": 150},\n",
    "            {\"in_features\": 150, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_2_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 400},\n",
    "            {\"in_features\": 400, \"out_features\": 300},\n",
    "            {\"in_features\": 300, \"out_features\": 150},\n",
    "            {\"in_features\": 150, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_2_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=8)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=8)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_3_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(120, 221, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 400},\n",
    "            {\"in_features\": 400, \"out_features\": 300},\n",
    "            {\"in_features\": 300, \"out_features\": 150},\n",
    "            {\"in_features\": 150, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_FNN_NORMAL_4_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Uniform Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.1 Zero To One Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=0, b=1)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_UNIFORM_0-1\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.2 Unit Variance And Zero Mean Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-math.sqrt(3), b=math.sqrt(3))\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_UNIFORM_PRE_ACT\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"deterministic\", a=-1.73, b=1.73)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_UNIFORM_PRE_ACT_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.3 Unit Variance and Zero Mean Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_UNIFORM_UNIT_VAR_ZERO_MEAN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "        {\"in_features\": 500, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"deterministic\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_FNN_UNIFORM_UNIT_VAR_ZERO_MEAN_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.5 Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Compare Our Approach To Others"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_FNN_TRIAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_fnn.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_fnn.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"normal\")\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_FNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_fnn_normal.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_fnn_normal.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal_in_features\", softmax_init=True)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_FNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_fnn_normal_in_last.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_fnn_normal_in_last.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"uniform\", a=0, b=1)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_FNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_fnn_uniform.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_fnn_uniform.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 28 * 28, \"out_features\": 500},\n",
    "            {\"in_features\": 500, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"uniform\", a=-1.29, b=2.5)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_FNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_fnn_uniform_unit_var.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_fnn_uniform_unit_var.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 MNIST - CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Normal Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32, flatten=False)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32, flatten=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", mean=-1.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_MEAN_NEG\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", mean=1.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_MEAN_POS\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", mean=-5.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_MEAN_NEG_HIGH\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", mean=5.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_MEAN_POS_HIGH\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", mean=-50.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_MEAN_NEG_OVER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", mean=50.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_MEAN_POS_OVER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal_in_features\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_IN_FEATURES\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", scale_factor=ELU_SCALE_NORMAL)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_ELU_SCALE\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"normal_in_features\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_IN_FEATURES_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", scale_factor=0.1)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_0.1_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", scale_factor=0.5)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_0.5_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", scale_factor=2.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_NORMAL_2.0_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.1 Finding The Point Of Break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 31, 2)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_1_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 31, 2)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 8, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 8, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 16 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_2_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 31, 2)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_3_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 31, 2)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 100},\n",
    "            {\"in_features\": 100, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_4_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/MNIST_CNN_NORMAL_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Uniform Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_mnist_loader(train=True, batch_size=32, flatten=False)\n",
    "test_loader = get_mnist_loader(train=False, batch_size=32, flatten=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.1 Zero To One Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(\"uniform\", a=0, b=1)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_UNIFORM_0-1\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.2 Unit Variance And Zero Mean Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(mode=\"uniform\", a=-math.sqrt(3), b=math.sqrt(3))\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_UNIFORM_PRE_ACT\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(mode=\"deterministic\", a=-math.sqrt(3), b=math.sqrt(3))\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_UNIFORM_PRE_ACT_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.3 Unit Variance and Zero Mean Activation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(mode=\"uniform\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_UNIFORM_UNIT_VAR_ZERO_MEAN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    [\n",
    "        {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "        {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.initialize(mode=\"deterministic\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"MNIST_CNN_UNIFORM_UNIT_VAR_ZERO_MEAN_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.5 Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO do several runs"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Compare Our Approach To Others"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_CNN_TRIAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_cnn.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_cnn.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"normal\")\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_CNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_cnn_normal.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_cnn_normal.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"normal\", scale_factor=ELU_SCALE_NORMAL)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_CNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_cnn_normal_elu.pkl\"))\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_cnn_normal_elu.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"uniform\", a=0, b=1)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_CNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_cnn_uniform.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_cnn_uniform.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_mnist_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_mnist_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CNN(\n",
    "        [\n",
    "            {\"in_channels\": 1, \"out_channels\": 16, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2},\n",
    "            {\"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 5, \"stride\": 1, \"padding\": 2}\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            {\"in_features\": 32 * 28 * 28, \"out_features\": 10}\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"uniform\", a=-1.29, b=2.5)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/MNIST_CNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"mnist_cnn_uniform_unit_var.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"mnist_cnn_uniform_unit_var.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 CIFAR-10 - FNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Normal Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_cifar10_loader(train=True, batch_size=32)\n",
    "test_loader = get_cifar10_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", ELU_SCALE_NORMAL)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_ELU_SCALE\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal_in_features\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_IN_FEATURES\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal_in_features\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_IN_FEATURES_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", mean=-1.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_MEAN_NEG\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", mean=1.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_MEAN_POS\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", mean=-5.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_MEAN_NEG_HIGH\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", mean=5.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_MEAN_POS_HIGH\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", mean=-50.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_MEAN_NEG_OVER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", mean=50.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_MEAN_POS_OVER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", scale_factor=0.1)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_0.1_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", scale_factor=0.5)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_0.5_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(\"normal\", scale_factor=2.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_NORMAL_2.0_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.1 Finding The Point Of Break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_FNN_NORMAL_1_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_FNN_NORMAL_2_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_cifar10_loader(train=True, batch_size=8)\n",
    "test_loader = get_cifar10_loader(train=False, batch_size=8)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_FNN_NORMAL_3_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_FNN_NORMAL_4_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_FNN_NORMAL_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Uniform Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_cifar10_loader(train=True, batch_size=32)\n",
    "test_loader = get_cifar10_loader(train=False, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.1 Zero To One Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=0, b=1)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_UNIFORM_0-1\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.2 Unit Variance And Zero Mean Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-math.sqrt(3), b=math.sqrt(3))\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_UNIFORM_PRE_ACT\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"deterministic\", a=-1.73, b=1.73)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_UNIFORM_PRE_ACT_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.3 Unit Variance and Zero Mean Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"uniform\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_UNIFORM_UNIT_VAR_ZERO_MEAN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FNN(\n",
    "    [\n",
    "        {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 256},\n",
    "        {\"in_features\": 256, \"out_features\": 128},\n",
    "        {\"in_features\": 128, \"out_features\": 10},\n",
    "    ]\n",
    ")\n",
    "model.initialize(mode=\"deterministic\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_FNN_UNIFORM_UNIT_VAR_ZERO_MEAN_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.5 Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Compare Our Approach to Others"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_FNN_TRIAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_fnn.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_fnn.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"normal\", softmax_init=True)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_FNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_fnn_normal.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_fnn_normal.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"])\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = FNN(\n",
    "        [\n",
    "            {\"in_features\": 32 * 32 * 3, \"out_features\": 512},\n",
    "            {\"in_features\": 512, \"out_features\": 256},\n",
    "            {\"in_features\": 256, \"out_features\": 128},\n",
    "            {\"in_features\": 128, \"out_features\": 10},\n",
    "        ]\n",
    "    )\n",
    "    model.initialize(\"uniform\", a=0, b=1)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_FNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_fnn_uniform.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_fnn_uniform.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4 CIFAR-10 CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_cifar10_loader(train=True, batch_size=32, flatten=False)\n",
    "test_loader = get_cifar10_loader(train=False, batch_size=32, flatten=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Normal Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", ELU_SCALE_NORMAL)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_ELU_SCALE\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal_in_features\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_IN_FEATURES\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", mean=-1.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_MEAN_NEG\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", mean=1.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_MEAN_POS\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", mean=-5.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_MEAN_NEG_HIGH\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", mean=5.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_MEAN_POS_HIGH\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", mean=-50.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_MEAN_NEG_OVER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", mean=50.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_MEAN_POS_OVER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", scale_factor=0.1)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_0.1_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", scale_factor=0.5)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_0.5_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal\", scale_factor=2.0)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_2.0_STD\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(\"normal_in_features\", softmax_init=True)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_NORMAL_IN_FEATURES_LAST_LAYER\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RESNET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = ResNet50()\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_RESNET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = ResNet50()\n",
    "model.initialize(\"normal\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_RESNET_NORMAL\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = ResNet50()\n",
    "model.initialize(\"normal\", ELU_SCALE_NORMAL)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_RESNET_NORMAL_ELU_SCALE\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = ResNet50()\n",
    "model.initialize(mode=\"uniform\", a=0, b=1)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_RESNET_UNIFORM_0-1\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = ResNet50()\n",
    "model.initialize(mode=\"uniform\", a=-math.sqrt(3), b=math.sqrt(3))\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_RESNET_UNIFORM_PRE_ACT\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = ResNet50()\n",
    "model.initialize(mode=\"deterministic\", a=-1.73, b=1.73)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_RESNET_UNIFORM_PRE_ACT_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = ResNet50()\n",
    "model.initialize(mode=\"uniform\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_RESNET_UNIFORM_UNIT_VAR_ZERO_MEAN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = ResNet50()\n",
    "model.initialize(mode=\"deterministic\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_RESNET_UNIFORM_UNIT_VAR_ZERO_MEAN_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.1.1 Finding The Point of Break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "factor_range = range(10, 301, 10)\n",
    "\n",
    "for factor in factor_range:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    model = CIFARCNN()\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_CNN_NORMAL_1_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "factors = [10, 100, 1000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for factor in factors:\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    factor = 1 / factor\n",
    "\n",
    "    model = CIFARCNN()\n",
    "    model.initialize(mode=\"normal\", scale_factor=factor)\n",
    "    writer = SummaryWriter(f\"./results/CIFAR-10_CNN_NORMAL_DOWN_{factor}\")\n",
    "    trainer = Trainer(model=model, lr=0.001, writer=writer)\n",
    "\n",
    "    trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=30, train_summary=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Uniform Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, val_loader = get_cifar10_loader(train=True, batch_size=32, flatten=False)\n",
    "test_loader = get_cifar10_loader(train=False, batch_size=32, flatten=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.1 Zero To One Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(mode=\"uniform\", a=0, b=1)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_UNIFORM_0-1\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.2 Unit Variance And Zero Mean Pre-Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(mode=\"uniform\", a=-math.sqrt(3), b=math.sqrt(3))\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_UNIFORM_PRE_ACT\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(mode=\"deterministic\", a=-1.73, b=1.73)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_UNIFORM_PRE_ACT_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.3 Unit Variance and Zero Mean Activations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(mode=\"uniform\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_UNIFORM_UNIT_VAR_ZERO_MEAN\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CIFARCNN()\n",
    "model.initialize(mode=\"deterministic\", a=-3.437, b=2.222)\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=\"CIFAR-10_CNN_UNIFORM_UNIT_VAR_ZERO_MEAN_DET\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "run_experiments(model, config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.5 Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Compare Our Approach To Others"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CIFARCNN()\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_CNN_TRIAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_cnn.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_cnn.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CIFARCNN()\n",
    "    model.initialize(\"normal_in_features\")\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_CNN_TRIAL_NORMAL\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_cnn_normal.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_cnn_normal.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    torch.manual_seed(R_SEED)\n",
    "    random.seed(R_SEED)\n",
    "    np.random.seed(R_SEED)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [Adam, RMSprop, SGD]),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 64, 2),\n",
    "\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = get_cifar10_loader(train=True, batch_size=params[\"batch_size\"], flatten=False)\n",
    "    test_loader = get_cifar10_loader(train=False, batch_size=params[\"batch_size\"], flatten=False)\n",
    "\n",
    "    model = CIFARCNN()\n",
    "    model.initialize('uniform', a=0, b=1)\n",
    "\n",
    "    writer = SummaryWriter(\"./results/CIFAR_CNN_TRIAL_UNIFORM\")\n",
    "    trainer = Trainer(model=model, lr=params[\"learning_rate\"], optimizer=params[\"optimizer\"], writer=writer)\n",
    "    accuracy = trainer.train(train_loader=train_loader, test_loader=test_loader, num_epochs=15, trial=trial,\n",
    "                             train_summary=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=28)\n",
    "\n",
    "joblib.dump(study, os.path.join(\"results\", \"optuna\", \"cifar_cnn_uniform.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "study = joblib.load(os.path.join(\"results\", \"optuna\", \"cifar_cnn_uniform.pkl\"), 'r')\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))\n",
    "print(f\"final accuracy: {study.best_trial.value}\")\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
